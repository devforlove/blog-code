많은 서비스에서 선착순 로직을 구현하기 위해서 Redis를 많이 사용합니다. 
이러한 선착순 로직은 작은 서비스에서는 큰 문제가 없겠지만, 많은 트래픽을 처리하는 서비스에서는 기술적으로 많은 고민들을 하게 됩니다.

제가 생각했을 때, 많은 트래픽의 서비스에서 고민할 문제들을 정리해보았습니다.
그리고 제가 작성한 방법들은 Redis의 서버 증설 없이 대응할 수 있는 방법들에 대해 정리한 내용입니다. 

Redis 서버 증설을 해서 클러스터의 샤드를 증가하면 쉽게 해결할 수도 있지만, 서버 증설에 대해서도 고민할 부분들이 있다고 생각합니다. 
- 증설 비용
- 특정 시점에만 트래픽이 몰리면, 자원이 낭비된다. 

그래서 최대한 증설 없이 할 수 있는 방법들을 적용해보고, 마지막에 서버 증설을 고려해야 한다고 생각합니다. 

## 1. Redis 과부하 문제 
매일 정각에 수십만 명의 유저에게 방송 리스트, 포인트 적립 내역 등을 Redis에 저장한다면, 유저가 늘어나면 늘어날수록 Redis 커맨드와 캐싱하는 데이터 양이 급격하게 늘어날 것입니다.
만약 Redis에 캐싱을 많이 하는 서비스라면, Redis의 과부하가 데이터베이스의 과부하로도 이어질 수 있다고 생각합니다.

Redis 과부하를 방지하려면 Redis가 캐싱하는 데이터와 읽고 쓰는 시점을 체크해야 합니다. 보통 Redis에 캐싱하는 데이터는 두가지로 분류할 수 있습니다. 
- Universal Data
  - 모든 유저에게 동일하게 보이는 데이터 
- User-Specific Data
  - 특정 유저에게만 보이는 데이터 
    

### Universal Data 문제 & 해결책
Universal Data는 트래픽이 늘어날수록 한개의 키에 GET 커맨드가 굉장히 많이 발생하게 됩니다. Redis에 많은 읽기 요청을 보내면 Redis는 많은 CPU 부하를 겪게 됩니다. 또한 많은 요청이 Redis로 향하면서 네트워크 I/O도 증가하게 됩니다. 
커맨드가 밀려 Redis에서 지연이 발생할 수도 있고, 이는 Redis를 사용하는 모든 API에 지연을 발생시키는 원인이 되기도 합니다. 

이러한 문제는 Universal Data를 Local Cache에 캐싱하는 방법으로 해결할 수 있습니다. 
Local Cache에 저장한다면, Redis의 부하도 줄일 수 있고, Redis로 향하는 네트워크 I/O도 최소화할 수 있습니다. 


### User-Specific Data 문제 & 해결책 
User-Specific Data는 유저가 늘어날수록 캐싱해야 하는 데이터가 많아지고, Redis의 메모리 사용량이 늘어나는 문제가 발생할 수 있습니다. 
이런 경우 데이터 하나의 크기만 작아지더라도, 전체적인 메모리 사용량이 효과적으로 줄어들게 됩니다. 
